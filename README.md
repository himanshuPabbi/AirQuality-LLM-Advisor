# AQI-Grounded-LLM-Advisor
Groq-Powered Air Quality Chatbot & Performance Benchmark
This repository contains a Streamlit-based AI Chatbot designed to provide real-time air quality insights, powered by the low-latency Groq API. It also includes a separate script for benchmarking Groq's performance metrics (latency and throughput) against a batch of test queries.

ğŸš€ Key Features
Real-Time AQI Insights: Chatbot answers questions using the latest Air Quality Index (AQI) data.

Proactive Monitoring: Features a visual alert for the city with the highest recorded AQI.

Token-Optimized Context: Data loading samples the large dataset to create a small, efficient context for the LLM to minimize token usage and maximize speed.

Groq Latency Test: Includes a standalone Python script to benchmark the true Total Response Time (TRT) and calculate Tokens Per Second (TPS) for the Groq API.

Comprehensive Logging: All chat interactions and benchmark results are logged to CSV files for auditing and analysis.

ğŸ› ï¸ Getting Started
Follow these steps to set up and run the Streamlit application and the performance benchmark script.

Prerequisites
Python 3.9+

A Groq API Key (Get one from Groq Cloud)

The required AQI dataset files (must be placed in the project root):

city_day.csv

city_hour.csv

station_day.csv

station_hour.csv

stations.csv

Installation
Clone the Repository:

Bash

https://github.com/himanshuPabbi/AirQuality-LLM-Advisor
cd your-repo-name
Create a Virtual Environment:

Bash

python -m venv venv
source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
Install Dependencies: You will need a requirements.txt file listing all necessary libraries (streamlit, pandas, groq, python-dotenv, etc.).

Bash

pip install -r requirements.txt
Set Up Environment Variables: Create a file named .env in the root directory and add your Groq API Key:

Ini, TOML

# .env
GROQ_API_KEY="your_secret_groq_api_key"
ğŸ’» Usage
1. Run the Streamlit Chatbot (demo.py)
This launches the interactive application with the chat interface and the Batch Analysis tool in the sidebar.

Bash

streamlit run demo.py
Open your web browser and navigate to the address provided (usually http://localhost:8501).

2. Run the Performance Benchmark (demo2.py)
This script executes a batch of queries against the Groq API to measure latency and throughput.

Ensure you have the query file: Create or obtain a file named all_775_queries.txt containing one test query per line.

Execute the script:

Bash

python demo2.py
The results, including query, response, and Total Response Time (TRT), will be saved to groq_performance_data.csv.

ğŸ“‚ Project Structure
.
â”œâ”€â”€ demo.py                  # Main Streamlit Chatbot application and Batch Tool
â”œâ”€â”€ demo2.py                 # Groq Latency Performance Benchmark script
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ .env                     # Stores GROQ_API_KEY
â”œâ”€â”€ all_775_queries.txt      # Input file for the benchmark script (demo2.py)
â”œâ”€â”€ chat_log.csv             # Log of all chat and batch interactions (Generated)
â”œâ”€â”€ groq_performance_data.csv# Log of performance metrics (Generated by demo2.py)
â”œâ”€â”€ city_day.csv             # AQI Dataset (Prerequisite)
â””â”€â”€ ...                      # Other required dataset files
âœï¸ Contributing
Contributions are welcome! If you have suggestions for new features, data visualizations, or improvements to the benchmark script, please feel free to open an issue or submit a pull request.

Fork the repository.

Create your feature branch (git checkout -b feature/AmazingFeature).

Commit your changes (git commit -m 'Add some AmazingFeature').

Push to the branch (git push origin feature/AmazingFeature).

Open a Pull Request.

ğŸ“œ License
Distributed under the MIT License. See LICENSE for more information.

This video provides a guided, hands-on example of how to build and deploy an AI chatbot using Streamlit and Groq. Build a Chatbot App with Python, Streamlit and Groq
